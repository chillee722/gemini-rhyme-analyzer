import streamlit as st
import numpy as np
from scipy.spatial.distance import cosine
import json
import nltk
from nltk.corpus import cmudict
from typing import List, Tuple, Optional, Dict

# --- CMUDict ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ---
@st.cache_resource(show_spinner="CMUDict ì‚¬ì „ì„ ë¡œë“œ ì¤‘...")
def load_cmudict():
    """CMUDictë¥¼ ë¡œë“œí•˜ê³  í•„ìš”í•œ ê²½ìš° ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        nltk.data.find('corpora/cmudict')
    except LookupError:
        nltk.download('cmudict')
        
    return cmudict.dict()

p_dict = load_cmudict()

# =========================================================
# 1. ìŒì†Œ ì„ë² ë”© (ìµœì¢… ë²„ì „ ìœ ì§€)
# =========================================================

# ARPAbet ê¸°í˜¸ì— ì–¸ì–´í•™ì  íŠ¹ì§• ë°˜ì˜: [ëª¨ìŒ, ë¹„ìŒ, ë°œì„±, ì¡°ìŒìœ„ì¹˜, ì¡°ìŒë°©ë²•]
PHONEME_EMBEDDINGS: Dict[str, np.ndarray] = {
    # Vowels
    'AE': np.array([1.0, 0.1, 1.0, 0.2, 0.0]), 'IY': np.array([0.95, 0.1, 1.0, 0.0, 0.0]), 
    'IH': np.array([0.9, 0.1, 1.0, 0.1, 0.0]), 'AH': np.array([0.7, 0.2, 1.0, 0.5, 0.0]),
    'AY': np.array([0.9, 0.1, 1.0, 0.3, 0.1]), 'AO': np.array([0.9, 0.1, 1.0, 0.7, 0.1]),
    'OW': np.array([0.85, 0.1, 1.0, 0.8, 0.1]), 'AW': np.array([0.85, 0.1, 1.0, 0.6, 0.1]),
    'ER': np.array([0.6, 0.0, 1.0, 0.5, 0.5]),
    
    # Consonants (Flow, Consonance ê°•í™”)
    'T': np.array([0.0, 0.75, 0.0, 0.4, 0.9]), 'D': np.array([0.0, 0.75, 1.0, 0.4, 0.9]), 
    'S': np.array([0.0, 0.0, 0.0, 0.35, 0.7]), 'Z': np.array([0.0, 0.0, 1.0, 0.35, 0.7]),
    'N': np.array([0.0, 0.9, 1.0, 0.4, 0.8]), 'M': np.array([0.0, 0.9, 1.0, 0.2, 0.8]), 
    'K': np.array([0.0, 0.5, 0.0, 0.8, 0.9]), 'G': np.array([0.0, 0.5, 1.0, 0.8, 0.9]),
    'F': np.array([0.0, 0.5, 0.0, 0.1, 0.7]), 'V': np.array([0.0, 0.5, 1.0, 0.1, 0.7]),

    # L/R/Y/W ê³„ì—´ (í™œìŒ/ìœ ìŒ ìœ ì‚¬ì„± ê·¹ëŒ€í™”)
    'L': np.array([0.6, 0.0, 1.0, 0.7, 0.3]), 'R': np.array([0.6, 0.0, 1.0, 0.5, 0.4]),
    'Y': np.array([0.7, 0.0, 1.0, 0.1, 0.1]), 'W': np.array([0.7, 0.0, 1.0, 0.9, 0.1]), 
}

def get_embedding(phon: str) -> np.ndarray:
    """ì •ì˜ëœ ìŒì†Œ ì„ë² ë”©ì„ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ 0 ë²¡í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return PHONEME_EMBEDDINGS.get(phon.upper(), np.zeros(5))

# =========================================================
# 2. í•µì‹¬ í•¨ìˆ˜: ë¼ì„ ìœ ë‹› ì¶”ì¶œ ë° ì ìˆ˜ ê³„ì‚°
# =========================================================

def get_rhyme_unit(word: str) -> Optional[Tuple[List[str], List[str], List[str]]]:
    """ë‹¨ì–´ì˜ ë§ˆì§€ë§‰ ê°•ì„¸ ëª¨ìŒ(1 ë˜ëŠ” 2)ì„ ê¸°ì¤€ìœ¼ë¡œ Rhyme Unitê³¼ Onsetì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    word = word.lower()
    if word not in p_dict:
        return None
        
    pron_raw = p_dict[word][0]
    stress_markers = ['1', '2']
    stress_indices = [i for i, phon in enumerate(pron_raw) if phon[-1] in stress_markers]
    
    if not stress_indices:
        start_index = 0
    else:
        start_index = stress_indices[-1]
        
    onset_raw = pron_raw[:start_index] 
    rhyme_unit_raw = pron_raw[start_index:]
    
    onset_clean = [phon.rstrip('0123') for phon in onset_raw]
    rhyme_unit_clean = [phon.rstrip('0123') for phon in rhyme_unit_raw]

    return pron_raw, onset_clean, rhyme_unit_clean


def calculate_front_rhyme_score(onset_list1: List[str], onset_list2: List[str]) -> float:
    """Onset(ë‘ìŒ) ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ Front Rhyme ì ìˆ˜ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤."""
    
    if not onset_list1 or not onset_list2:
        return 0.0
        
    # ë¹„êµë¥¼ ìœ„í•´ ê°€ì¥ ì§§ì€ Onset ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§ì¶¥ë‹ˆë‹¤.
    min_len = min(len(onset_list1), len(onset_list2))
    
    vec1_list = [get_embedding(p) for p in onset_list1[-min_len:]]
    vec2_list = [get_embedding(p) for p in onset_list2[-min_len:]]
    
    vec1 = np.concatenate(vec1_list)
    vec2 = np.concatenate(vec2_list)
    
    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
        return 0.0

    return max(0, 1 - cosine(vec1, vec2))


def arpabet_to_ipa(arpabet_phons: List[str]) -> Optional[str]:
    """ARPAbet ìŒì†Œì—´ì„ IPA ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    ARPABET_TO_IPA_MAP = {
        'AA': 'É‘', 'AE': 'Ã¦', 'AH': 'ÊŒ', 'AO': 'É”', 'AW': 'aÊŠ', 'AY': 'aÉª', 'B': 'b', 'CH': 'Ê§', 'D': 'd', 'DH': 'Ã°', 'EH': 'É›', 'ER': 'É™É¹', 'EY': 'eÉª', 'F': 'f', 'G': 'g', 'HH': 'h', 'IH': 'Éª', 'IY': 'i', 'JH': 'Ê¤', 'K': 'k', 'L': 'l', 'M': 'm', 'N': 'n', 'NG': 'Å‹', 'OW': 'oÊŠ', 'OY': 'É”Éª', 'P': 'p', 'R': 'r', 'S': 's', 'SH': 'Êƒ', 'T': 't', 'TH': 'Î¸', 'UH': 'ÊŠ', 'UW': 'u', 'V': 'v', 'W': 'w', 'Y': 'j', 'Z': 'z', 'ZH': 'Ê’',
    }
    ipa_phons = [ARPABET_TO_IPA_MAP.get(phon.upper(), '') for phon in arpabet_phons]
    return "".join([p for p in ipa_phons if p])


def calculate_slant_score(phon_list1: List[str], phon_list2: List[str], target_vowel: str, candidate_vowel: str) -> float:
    """Rhyme Unit ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (Score > 1.0 ë²„ê·¸ ìˆ˜ì •ë¨)"""
    len1, len2 = len(phon_list1), len(phon_list2)
    max_len = max(len1, len2)
    
    vec1_list = [get_embedding(p) for p in phon_list1]
    vec2_list = [get_embedding(p) for p in phon_list2]
    
    vec1 = np.concatenate(vec1_list + [np.zeros(5)] * (max_len - len1))
    vec2 = np.concatenate(vec2_list + [np.zeros(5)] * (max_len - len2))
    
    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
        return 0.0

    similarity = 1 - cosine(vec1, vec2)
    
    vowel_bonus = 0.0
    if target_vowel and target_vowel == candidate_vowel:
        vowel_bonus = 0.05 

    final_score = similarity + vowel_bonus
    # Score > 1.0 ë²„ê·¸ ìˆ˜ì •: ìµœëŒ€ê°’ì„ 1.0ìœ¼ë¡œ ì„¤ì •
    return min(1.0, max(0, final_score))


@st.cache_data(show_spinner=False)
def get_rhyme_candidates_with_score(target_word: str, top_n=100) -> Dict:
    """ë¼ì„ ìœ í˜•ë³„ë¡œ ë¶„ë¥˜í•˜ì—¬ í›„ë³´ ë‹¨ì–´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    
    target_info = get_rhyme_unit(target_word)
    
    if not target_info:
        return {"target_word": target_word, "target_ipa": "N/A", "target_rhyme_unit": "N/A", "raw_arpabet": "N/A", "candidates": []}

    target_pron_raw, target_onset, target_rhyme_unit = target_info
    target_ipa = arpabet_to_ipa(target_rhyme_unit)
    target_vowel = target_rhyme_unit[0] if target_rhyme_unit else ""
    target_rhyme_len = len(target_rhyme_unit)
    
    if not target_ipa or not target_rhyme_unit:
        return {"target_word": target_word, "target_ipa": "N/A", "target_rhyme_unit": "N/A", "raw_arpabet": target_pron_raw, "candidates": []}

    # ìµœì¢… ì¶œë ¥ì„ ìœ„í•œ ë¶„ë¥˜ ë”•ì…”ë„ˆë¦¬
    classified_candidates = {
        "holorhymes": [], # Front Rhyme + End Rhyme ëª¨ë‘ ë†’ì€ ì ìˆ˜
        "front_rhymes": [], # Front Rhymeë§Œ ë†’ì€ ì ìˆ˜
        "end_rhymes": [], # End Rhymeë§Œ ë†’ì€ ì ìˆ˜
    }
    
    # ì ìˆ˜ ê¸°ì¤€ (ì„ê³„ê°’ ì„¤ì •)
    RHYME_THRESHOLD = 0.85
    
    for word, _ in p_dict.items():
        
        candidate_info = get_rhyme_unit(word)
        if not candidate_info:
            continue
            
        candidate_pron_raw, candidate_onset, candidate_rhyme_unit = candidate_info
        
        if word == target_word.lower():
            continue
            
        # A. Perfect Rhyme ê²€ì‚¬ (ì™„ë²½ ë¼ì„ì€ ì œì™¸)
        if len(candidate_rhyme_unit) == target_rhyme_len and candidate_rhyme_unit == target_rhyme_unit:
            is_onset_different = (not target_onset or not candidate_onset or target_onset[-1] != candidate_onset[-1])
            if is_onset_different:
                continue # ì™„ë²½ ë¼ì„ ì œì™¸

        # B. Front/End Rhyme ì ìˆ˜ ê³„ì‚°
        
        # 1. End Rhyme Score (Rhyme Unit ìœ ì‚¬ë„)
        end_score = calculate_slant_score(target_rhyme_unit, candidate_rhyme_unit, target_vowel, candidate_vowel)
        
        # 2. Front Rhyme Score (Onset ìœ ì‚¬ë„)
        front_score = 0.0
        if target_onset and candidate_onset:
            front_score = calculate_front_rhyme_score(target_onset, candidate_onset)
        
        # 3. ë¶„ë¥˜
        is_front_match = front_score >= RHYME_THRESHOLD
        is_end_match = end_score >= RHYME_THRESHOLD
        
        if is_front_match and is_end_match:
            # Holorime / Mosaic Rhyme (ì–‘ìª½ ëª¨ë‘ ë†’ì€ ì ìˆ˜)
            classified_candidates["holorhymes"].append({
                "word": word,
                "end_score": round(end_score, 4),
                "front_score": round(front_score, 4),
                "ipa": arpabet_to_ipa(candidate_rhyme_unit),
                "rhyme_unit": " ".join(candidate_rhyme_unit),
            })
        elif is_front_match:
            # Front Rhyme (ì•ë¶€ë¶„ë§Œ ë†’ì€ ì ìˆ˜)
            classified_candidates["front_rhymes"].append({
                "word": word,
                "front_score": round(front_score, 4),
                "end_score": round(end_score, 4),
                "ipa": arpabet_to_ipa(candidate_rhyme_unit),
                "rhyme_unit": " ".join(candidate_rhyme_unit),
            })
        elif is_end_match:
            # End Rhyme (ë’·ë¶€ë¶„ë§Œ ë†’ì€ ì ìˆ˜)
            classified_candidates["end_rhymes"].append({
                "word": word,
                "end_score": round(end_score, 4),
                "front_score": round(front_score, 4),
                "ipa": arpabet_to_ipa(candidate_rhyme_unit),
                "rhyme_unit": " ".join(candidate_rhyme_unit),
            })

    # ë¶„ë¥˜ëœ ëª©ë¡ì„ ì ìˆ˜(End Score) ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    for key in classified_candidates:
        classified_candidates[key].sort(key=lambda x: x['end_score'], reverse=True)


    # ìµœì¢… ì¶œë ¥ì„ ìœ„í•´ ë¶„ë¥˜ëœ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì¬êµ¬ì„±
    final_output = {
        "target_word": target_word,
        "target_ipa": target_ipa,
        "target_rhyme_unit": " ".join(target_rhyme_unit),
        "classified_rhymes": classified_candidates
    }
    
    return final_output


# =========================================================
# 3. Streamlit UI (ìµœì¢…)
# =========================================================

st.set_page_config(page_title="Phonetics Analyzer (Rhyme Classification)", layout="wide")

st.title("ğŸ¤ CMUDict í†µí•©: ì—ë¯¸ë„´ ìŠ¤íƒ€ì¼ ë¼ì„ ë¶„ë¥˜ ë¶„ì„ê¸°")
st.caption("âœ… Front Rhymeê³¼ End Rhymeì„ **ë…ë¦½ì ì¸ ì ìˆ˜**ë¡œ ê³„ì‚°í•˜ì—¬ ë³µí•© ë¼ì„ êµ¬ì„±ì„ ë•ìŠµë‹ˆë‹¤.")

# ì‚¬ìš©ì ì…ë ¥
input_word = st.text_input("ë¶„ì„í•  ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: lawyer, nervous, controversy)", "nervous")

if input_word:
    st.subheader(f"ğŸ” '{input_word}'ì— ëŒ€í•œ CMUDict ê¸°ë°˜ ë¶„ì„ ê²°ê³¼")
    
    with st.spinner('CMUDictë¥¼ ìŠ¤ìº”í•˜ê³  ë¼ì„ ìœ ë‹›ì„ ê³„ì‚° ì¤‘...'):
        analysis_result = get_rhyme_candidates_with_score(input_word)
    
    # --- ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ ---
    st.markdown("#### ğŸš¨ ë””ë²„ê¹… ë° ë¶„ì„ ì •ë³´")
    st.markdown(f"**ëŒ€ìƒ ë¼ì„ ìœ ë‹› (IPA):** `{analysis_result['target_ipa']}`")
    
    st.markdown("---")
    st.markdown("#### ğŸ† ë¼ì„ ë¶„ë¥˜ ê²°ê³¼ (End Score ìˆœ ì •ë ¬)")
    
    # 1. Holorime / Mosaic Rhyme ì¶œë ¥
    st.markdown("##### 1. Holorime / Mosaic Rhyme (ì „ì²´ ì†Œë¦¬ ë¸”ë¡ ìœ ì‚¬ì„±)")
    if analysis_result['classified_rhymes']['holorhymes']:
        st.dataframe(analysis_result['classified_rhymes']['holorhymes'], use_container_width=True, hide_index=True)
    else:
        st.info("í•´ë‹¹ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ” ë³µí•© ë¼ì„ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 2. Front Rhyme ì¶œë ¥
    st.markdown("##### 2. Front Rhyme (ë‘ìŒ ìœ ì‚¬ì„±: Chain Rhymeì— ì í•©)")
    if analysis_result['classified_rhymes']['front_rhymes']:
        st.dataframe(analysis_result['classified_rhymes']['front_rhymes'], use_container_width=True, hide_index=True)
    else:
        st.info("í•´ë‹¹ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ” Front Rhyme í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # 3. End Rhyme ì¶œë ¥
    st.markdown("##### 3. End Rhyme (ëì†Œë¦¬ ìœ ì‚¬ì„±: ì „í†µì ì¸ Slant Rhyme)")
    if analysis_result['classified_rhymes']['end_rhymes']:
        st.dataframe(analysis_result['classified_rhymes']['end_rhymes'], use_container_width=True, hide_index=True)
    else:
        st.info("í•´ë‹¹ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ” End Rhyme í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 4. JSON ì¶œë ¥
    st.markdown("---")
    st.markdown("#### ğŸ¤– Geminiì—ê²Œ ì œê³µí•  ìµœì¢… API ì‘ë‹µ (JSON)")
    st.code(json.dumps(analysis_result, indent=2), language='json')
