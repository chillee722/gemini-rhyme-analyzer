import streamlit as st
import numpy as np
from scipy.spatial.distance import cosine
import json
import nltk
from nltk.corpus import cmudict
from typing import List, Tuple, Optional, Dict

# --- CMUDict ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ---
@st.cache_resource(show_spinner="CMUDict ì‚¬ì „ì„ ë¡œë“œ ì¤‘...")
def load_cmudict():
    """CMUDictë¥¼ ë¡œë“œí•˜ê³  í•„ìš”í•œ ê²½ìš° ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        nltk.data.find('corpora/cmudict')
    except LookupError:
        nltk.download('cmudict')
        
    return cmudict.dict()

p_dict = load_cmudict()

# =========================================================
# 1. ìŒì†Œ ì„ë² ë”© (ìµœì¢… ë²„ì „ ìœ ì§€)
# =========================================================

# ARPAbet ê¸°í˜¸ì— ì–¸ì–´í•™ì  íŠ¹ì§• ë°˜ì˜: [ëª¨ìŒ, ë¹„ìŒ, ë°œì„±, ì¡°ìŒìœ„ì¹˜, ì¡°ìŒë°©ë²•]
PHONEME_EMBEDDINGS: Dict[str, np.ndarray] = {
    # Vowels
    'AE': np.array([1.0, 0.1, 1.0, 0.2, 0.0]), 'IY': np.array([0.95, 0.1, 1.0, 0.0, 0.0]), 
    'IH': np.array([0.9, 0.1, 1.0, 0.1, 0.0]), 'AH': np.array([0.7, 0.2, 1.0, 0.5, 0.0]),
    'AY': np.array([0.9, 0.1, 1.0, 0.3, 0.1]), 'AO': np.array([0.9, 0.1, 1.0, 0.7, 0.1]),
    'OW': np.array([0.85, 0.1, 1.0, 0.8, 0.1]), 'AW': np.array([0.85, 0.1, 1.0, 0.6, 0.1]),
    'ER': np.array([0.6, 0.0, 1.0, 0.5, 0.5]),
    
    # Consonants (Flow, Consonance ê°•í™”)
    'T': np.array([0.0, 0.75, 0.0, 0.4, 0.9]), 'D': np.array([0.0, 0.75, 1.0, 0.4, 0.9]), 
    'S': np.array([0.0, 0.0, 0.0, 0.35, 0.7]), 'Z': np.array([0.0, 0.0, 1.0, 0.35, 0.7]),
    'N': np.array([0.0, 0.9, 1.0, 0.4, 0.8]), 'M': np.array([0.0, 0.9, 1.0, 0.2, 0.8]), 
    'K': np.array([0.0, 0.5, 0.0, 0.8, 0.9]), 'G': np.array([0.0, 0.5, 1.0, 0.8, 0.9]),
    'F': np.array([0.0, 0.5, 0.0, 0.1, 0.7]), 'V': np.array([0.0, 0.5, 1.0, 0.1, 0.7]),

    # L/R/Y/W ê³„ì—´ (í™œìŒ/ìœ ìŒ ìœ ì‚¬ì„± ê·¹ëŒ€í™”)
    'L': np.array([0.6, 0.0, 1.0, 0.7, 0.3]), 'R': np.array([0.6, 0.0, 1.0, 0.5, 0.4]),
    'Y': np.array([0.7, 0.0, 1.0, 0.1, 0.1]), 'W': np.array([0.7, 0.0, 1.0, 0.9, 0.1]), 
}

def get_embedding(phon: str) -> np.ndarray:
    """ì •ì˜ëœ ìŒì†Œ ì„ë² ë”©ì„ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ 0 ë²¡í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return PHONEME_EMBEDDINGS.get(phon.upper(), np.zeros(5))

# =========================================================
# 2. í•µì‹¬ í•¨ìˆ˜: ë¼ì„ ìœ ë‹› ì¶”ì¶œ ë° ì ìˆ˜ ê³„ì‚°
# =========================================================

def get_rhyme_unit(word: str) -> Optional[Tuple[List[str], List[str], List[str]]]:
    """ë‹¨ì–´ì˜ ë§ˆì§€ë§‰ ê°•ì„¸ ëª¨ìŒ(1 ë˜ëŠ” 2)ì„ ê¸°ì¤€ìœ¼ë¡œ Rhyme Unitê³¼ Onsetì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    word = word.lower()
    if word not in p_dict:
        return None
        
    pron_raw = p_dict[word][0]
    stress_markers = ['1', '2']
    stress_indices = [i for i, phon in enumerate(pron_raw) if phon[-1] in stress_markers]
    
    if not stress_indices:
        start_index = 0
    else:
        start_index = stress_indices[-1]
        
    onset_raw = pron_raw[:start_index] 
    rhyme_unit_raw = pron_raw[start_index:]
    
    # ìŠ¤íŠ¸ë ˆìŠ¤ ë§ˆí¬ ì œê±°
    onset_clean = [phon.rstrip('0123') for phon in onset_raw]
    rhyme_unit_clean = [phon.rstrip('0123') for phon in rhyme_unit_raw]

    # ë°˜í™˜: (ì›ë³¸ ë°œìŒ, Onset, Rhyme Unit)
    return pron_raw, onset_clean, rhyme_unit_clean


def calculate_front_rhyme_score(onset_list1: List[str], onset_list2: List[str]) -> float:
    """Onset(ë‘ìŒ) ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ Front Rhyme ì ìˆ˜ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤."""
    
    if not onset_list1 or not onset_list2:
        return 0.0
        
    # ë¹„êµë¥¼ ìœ„í•´ ê°€ì¥ ì§§ì€ Onset ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§ì¶¥ë‹ˆë‹¤.
    min_len = min(len(onset_list1), len(onset_list2))
    
    vec1_list = [get_embedding(p) for p in onset_list1[-min_len:]]
    vec2_list = [get_embedding(p) for p in onset_list2[-min_len:]]
    
    vec1 = np.concatenate(vec1_list)
    vec2 = np.concatenate(vec2_list)
    
    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
        return 0.0

    # ìœ ì‚¬ë„ê°€ ë†’ì„ìˆ˜ë¡ 1ì— ê°€ê¹ìŠµë‹ˆë‹¤.
    return max(0, 1 - cosine(vec1, vec2))


def calculate_slant_score(phon_list1: List[str], phon_list2: List[str], target_vowel: str, candidate_vowel: str) -> float:
    """Rhyme Unit ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (Score > 1.0 ë²„ê·¸ ìˆ˜ì •ë¨)"""
    len1, len2 = len(phon_list1), len(phon_list2)
    max_len = max(len1, len2)
    
    vec1_list = [get_embedding(p) for p in phon_list1]
    vec2_list = [get_embedding(p) for p in phon_list2]
    
    vec1 = np.concatenate(vec1_list + [np.zeros(5)] * (max_len - len1))
    vec2 = np.concatenate(vec2_list + [np.zeros(5)] * (max_len - len2))
    
    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
        return 0.0

    similarity = 1 - cosine(vec1, vec2)
    
    vowel_bonus = 0.0
    if target_vowel and target_vowel == candidate_vowel:
        vowel_bonus = 0.05 

    final_score = similarity + vowel_bonus
    # Score > 1.0 ë²„ê·¸ ìˆ˜ì •: ìµœëŒ€ê°’ì„ 1.0ìœ¼ë¡œ ì„¤ì •
    return min(1.0, max(0, final_score))


@st.cache_data(show_spinner=False)
def get_rhyme_candidates_with_score(target_word: str, top_n=100) -> Dict:
    """Front Rhyme ì ìˆ˜ë¥¼ í¬í•¨í•˜ì—¬ ë¼ì„ í›„ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    
    target_info = get_rhyme_unit(target_word)
    
    if not target_info:
        return {"target_word": target_word, "target_ipa": "N/A", "target_rhyme_unit": "N/A", "raw_arpabet": "N/A", "candidates": []}

    target_pron_raw, target_onset, target_rhyme_unit = target_info
    target_ipa = arpabet_to_ipa(target_rhyme_unit)
    target_vowel = target_rhyme_unit[0] if target_rhyme_unit else ""
    target_rhyme_len = len(target_rhyme_unit)
    
    if not target_ipa or not target_rhyme_unit:
        return {"target_word": target_word, "target_ipa": "N/A", "target_rhyme_unit": "N/A", "raw_arpabet": target_pron_raw, "candidates": []}

    candidates_list = []
    
    # --- Front Rhyme êµ¬í˜„ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ---
    # Rhyme Unit ìœ ì‚¬ë„(Slant Score)ì— Front Rhyme ìœ ì‚¬ë„ë¥¼ í•©ì‚°í•  ë¹„ìœ¨ (ê°€ì¤‘ì¹˜)
    FRONT_RHYME_WEIGHT = 0.1 
    # ------------------------------------------

    for word, _ in p_dict.items():
        
        candidate_info = get_rhyme_unit(word)
        if not candidate_info:
            continue
            
        candidate_pron_raw, candidate_onset, candidate_rhyme_unit = candidate_info
        
        if word == target_word.lower():
            continue
            
        score = 0.0
        rhyme_type = "Slant/Poor Match"
        candidate_vowel = candidate_rhyme_unit[0] if candidate_rhyme_unit else ""
        
        # A. Perfect Rhyme ê²€ì‚¬ (ì™„ë²½ ë¼ì„ì€ ì œì™¸)
        is_perfect = False
        if len(candidate_rhyme_unit) == target_rhyme_len and candidate_rhyme_unit == target_rhyme_unit:
            is_onset_different = (not target_onset or not candidate_onset or target_onset[-1] != candidate_onset[-1])
            if is_onset_different:
                is_perfect = True

        if is_perfect:
            continue # ì™„ë²½ ë¼ì„ ì œì™¸

        # B. Slant Rhyme ë° Front Rhyme êµ¬í˜„
        len_diff = abs(len(candidate_rhyme_unit) - target_rhyme_len)
        
        if len_diff <= 2: 
            
            # 1. Rhyme Unit ìœ ì‚¬ë„ ê³„ì‚° (ë©”ì¸)
            slant_score_base = calculate_slant_score(target_rhyme_unit, candidate_rhyme_unit, target_vowel, candidate_vowel)
            
            # 2. Front Rhyme ìœ ì‚¬ë„ ê³„ì‚° (ë³´ë„ˆìŠ¤)
            front_rhyme_similarity = 0.0
            if target_onset and candidate_onset:
                front_rhyme_similarity = calculate_front_rhyme_score(target_onset, candidate_onset)
                
            # 3. ìµœì¢… ì ìˆ˜: Rhyme Unit ìœ ì‚¬ë„ + Front Rhyme ë³´ë„ˆìŠ¤
            # (ì´ì ì€ 1.0ìœ¼ë¡œ ë‹¤ì‹œ ìº¡ì„ ì”Œì›Œ ì˜¤ë²„í”Œë¡œìš° ë°©ì§€)
            final_weighted_score = slant_score_base + (front_rhyme_similarity * FRONT_RHYME_WEIGHT)
            score = min(1.0, final_weighted_score)
            
            # ë“±ê¸‰ ë¶„ë¥˜
            if score >= 0.95: 
                rhyme_type = "Multi-Syllable Slant/Front Rhyme (Near Perfect)"
            elif score >= 0.85:
                rhyme_type = "Slant/Front Rhyme (Good Match)"
            else:
                continue 
        else:
            continue 

        if score > 0.0:
            candidates_list.append({
                "word": word,
                "score": round(score, 4), 
                "ipa": arpabet_to_ipa(candidate_rhyme_unit),
                "rhyme_unit": " ".join(candidate_rhyme_unit),
                "rhyme_type": rhyme_type
            })

    candidates_list.sort(key=lambda x: x['score'], reverse=True)

    return {
        "target_word": target_word,
        "target_ipa": target_ipa,
        "target_rhyme_unit": " ".join(target_rhyme_unit),
        "raw_arpabet": target_pron_raw,
        "candidates": candidates_list[:top_n]
    }


# =========================================================
# 3. Streamlit UI (ìµœì¢…)
# =========================================================

st.set_page_config(page_title="Phonetics Analyzer (Front Rhyme Final)", layout="centered")

st.title("ğŸ¤ CMUDict í†µí•©: ì—ë¯¸ë„´ ìŠ¤íƒ€ì¼ ê³ ê¸‰ ë¼ì„ ë¶„ì„ê¸° (ìµœì¢…)")
st.caption("âœ… **Front Rhyme(ë‘ìŒ ìœ ì‚¬ë„)ì„ ëª…ì‹œì ìœ¼ë¡œ ê³„ì‚°**í•˜ê³  ì ìˆ˜ì— ë°˜ì˜í•˜ì—¬ ë³µí•© ë¼ì„ì„ êµ¬í˜„í•©ë‹ˆë‹¤. Score ë²„ê·¸ ìˆ˜ì • ì™„ë£Œ.")

# ì‚¬ìš©ì ì…ë ¥
input_word = st.text_input("ë¶„ì„í•  ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: together, recently, lawyer)", "recently")

if input_word:
    st.subheader(f"ğŸ” '{input_word}'ì— ëŒ€í•œ CMUDict ê¸°ë°˜ ë¶„ì„ ê²°ê³¼")
    
    # ê³„ì‚° ë¡œì§ ì‹¤í–‰
    with st.spinner('CMUDictë¥¼ ìŠ¤ìº”í•˜ê³  ë¼ì„ ìœ ë‹›ì„ ê³„ì‚° ì¤‘...'):
        analysis_result = get_rhyme_candidates_with_score(input_word)
    
    # --- ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ ---
    st.markdown("#### ğŸš¨ ë””ë²„ê¹… ë° ë¶„ì„ ì •ë³´")
    st.markdown(f"**CMUDict ì›ë³¸ ë°œìŒ (ARPAbet):** `{analysis_result.get('raw_arpabet')}`")
    st.markdown(f"**ëŒ€ìƒ ë¼ì„ ìœ ë‹› (ARPAbet):** `{analysis_result['target_rhyme_unit']}`")
    st.markdown(f"**ëŒ€ìƒ ë¼ì„ ìœ ë‹› (IPA):** `{analysis_result['target_ipa']}`")
    
    # 2. ìœ ì‚¬ë„ í…Œì´ë¸” í‘œì‹œ
    st.markdown("---")
    st.markdown("#### CMUDict ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ (ì ìˆ˜ ìˆœ ì •ë ¬)")
    
    if analysis_result['candidates']:
        # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
        data = []
        for c in analysis_result['candidates']:
            data.append({
                "Word": c['word'],
                "Rhyme Unit (ARPAbet)": c['rhyme_unit'],
                "IPA": c['ipa'],
                "Score": f"{c['score']:.4f}",
                "Rhyme Type": c['rhyme_type']
            })
        
        st.dataframe(data, use_container_width=True, hide_index=True)
    else:
        st.warning(f"CMUDictì—ì„œ '{input_word}'ì— ëŒ€í•œ ì ì ˆí•œ ìŠ¬ëœíŠ¸ ë¼ì„ í›„ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì™„ë²½ ë¼ì„ ì œì™¸)")

    # 3. Geminiê°€ ë°›ì„ API ì‘ë‹µ (JSON)
    st.markdown("---")
    st.markdown("#### ğŸ¤– Geminiì—ê²Œ ì œê³µí•  ìµœì¢… API ì‘ë‹µ (JSON)")
    final_json_output = {
        "target_word": analysis_result["target_word"],
        "target_ipa": analysis_result["target_ipa"],
        "candidates": [{k: v for k, v in c.items() if k not in ['rhyme_unit']} for c in analysis_result["candidates"]]
    }
    st.code(json.dumps(final_json_output, indent=2), language='json')
