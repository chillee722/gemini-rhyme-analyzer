import streamlit as st
import numpy as np
from scipy.spatial.distance import cosine
import json
import nltk
from nltk.corpus import cmudict
from typing import List, Tuple, Optional, Dict

# --- CMUDict ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ---
@st.cache_resource(show_spinner="CMUDict ì‚¬ì „ì„ ë¡œë“œ ì¤‘...")
def load_cmudict():
    """CMUDictë¥¼ ë¡œë“œí•˜ê³  í•„ìš”í•œ ê²½ìš° ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        nltk.data.find('corpora/cmudict')
    except LookupError:
        nltk.download('cmudict')
        
    return cmudict.dict()

p_dict = load_cmudict()

# =========================================================
# 1. ìŒì†Œ ì„ë² ë”© (Slant Rhyme ê³„ì‚°ìš©: ëª¨ìŒ/ììŒ ìœ ì‚¬ë„ ê°•í™”)
# =========================================================

# ARPAbet ê¸°í˜¸ì— ì–¸ì–´í•™ì  íŠ¹ì§•ì„ ë°˜ì˜í•œ ë²¡í„° ì •ì˜ (ì˜ˆì‹œ: 5ì°¨ì›)
PHONEME_EMBEDDINGS: Dict[str, np.ndarray] = {
    # Vowels (ëª¨ìŒ): 
    'AE': np.array([1.0, 0.1, 0.2, 0.0, 1.0]),  # 'cat' (Ã¦)
    'IY': np.array([0.9, 0.1, 0.0, 0.0, 1.0]),  # 'feel' (i)
    'IH': np.array([0.8, 0.1, 0.1, 0.0, 1.0]),  # 'sit' (Éª) - IYì™€ ìœ ì‚¬
    'AH': np.array([0.7, 0.2, 0.5, 0.0, 1.0]),  # 'cut' (ÊŒ) 
    'ER': np.array([0.6, 0.0, 0.5, 0.5, 1.0]),  # 'R-colored' vowel
    
    # Consonants (ììŒ): 
    'T': np.array([0.0, 0.8, 0.2, 0.9, 0.0]),
    'D': np.array([0.0, 0.8, 0.2, 0.9, 1.0]), 
    'N': np.array([0.0, 0.9, 0.2, 0.8, 1.0]),
    'K': np.array([0.0, 0.5, 0.8, 0.9, 0.0]),
    'G': np.array([0.0, 0.5, 0.8, 0.9, 1.0]),
    'L': np.array([0.0, 0.0, 0.7, 0.4, 1.0]),
    'M': np.array([0.0, 0.9, 0.1, 0.8, 1.0]),
    'W': np.array([0.3, 0.0, 0.9, 0.3, 1.0]),
    'Y': np.array([0.3, 0.0, 0.1, 0.3, 1.0]),
    'R': np.array([0.1, 0.0, 0.5, 0.5, 1.0]),
    'S': np.array([0.0, 0.0, 0.2, 0.7, 0.0]),
}

def get_embedding(phon: str) -> np.ndarray:
    """ì •ì˜ëœ ìŒì†Œ ì„ë² ë”©ì„ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ 0 ë²¡í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return PHONEME_EMBEDDINGS.get(phon.upper(), np.zeros(5))

# =========================================================
# 2. í•µì‹¬ ìˆ˜ì • í•¨ìˆ˜: ë¼ì„ ìœ ë‹› ì¶”ì¶œ (ê°•ì„¸ ëª¨ìŒ ê¸°ì¤€)
# =========================================================

def get_rhyme_unit(word: str) -> Optional[Tuple[List[str], List[str], List[str], str]]:
    """
    ë‹¨ì–´ì˜ ë°œìŒì—ì„œ ë§ˆì§€ë§‰ ê°•ì„¸ ëª¨ìŒì„ ê¸°ì¤€ìœ¼ë¡œ ë¼ì„ ìœ ë‹›ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (ë°˜í™˜: ì›ë³¸ ë°œìŒ, Onset(ë‘ìŒ), Rhyme Unit(ìš´), Stressed Vowel)
    """
    word = word.lower()
    if word not in p_dict:
        return None
        
    pron_raw = p_dict[word][0]
    
    # ë§ˆì§€ë§‰ ê°•ì„¸ ëª¨ìŒ (1ì°¨ '1' ë˜ëŠ” 2ì°¨ '2')ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    stress_markers = ['1', '2']
    stress_indices = [i for i, phon in enumerate(pron_raw) if phon[-1] in stress_markers]
    
    if not stress_indices:
        # ê°•ì„¸ê°€ ì—†ëŠ” ë‹¨ì–´ëŠ” ì „ì²´ë¥¼ ë¼ì„ ìœ ë‹›ìœ¼ë¡œ ê°„ì£¼ (ì²« ìŒì†Œë¶€í„°)
        start_index = 0
    else:
        # ê°€ì¥ ë§ˆì§€ë§‰ ê°•ì„¸ ìœ„ì¹˜ë¥¼ ë¼ì„ ìœ ë‹›ì˜ ì‹œì‘ì ìœ¼ë¡œ ì‚¼ìŠµë‹ˆë‹¤.
        start_index = stress_indices[-1]
        
    # ë¼ì„ ìœ ë‹› ë¶„ë¦¬
    onset_raw = pron_raw[:start_index] 
    rhyme_unit_raw = pron_raw[start_index:]
    
    stressed_vowel_raw = rhyme_unit_raw[0] if rhyme_unit_raw else ""
    
    # ìŠ¤íŠ¸ë ˆìŠ¤ ë§ˆí¬ ì œê±° (ìˆœìˆ˜ ìŒì†Œë§Œ ë‚¨ê¹ë‹ˆë‹¤.)
    onset_clean = [phon.rstrip('0123') for phon in onset_raw]
    rhyme_unit_clean = [phon.rstrip('0123') for phon in rhyme_unit_raw]
    stressed_vowel_clean = stressed_vowel_raw.rstrip('0123')

    return pron_raw, onset_clean, rhyme_unit_clean, stressed_vowel_clean

# ---------------------------------------------------------
# IPA ë³€í™˜ í•¨ìˆ˜ (ë””ë²„ê¹… ë° í‘œì‹œìš©)
# ---------------------------------------------------------
ARPABET_TO_IPA_MAP = {
    'AA': 'É‘', 'AE': 'Ã¦', 'AH': 'ÊŒ', 'AO': 'É”', 'AW': 'aÊŠ', 'AY': 'aÉª', 'B': 'b', 'CH': 'Ê§', 'D': 'd', 'DH': 'Ã°', 'EH': 'É›', 'ER': 'É™É¹', 'EY': 'eÉª', 'F': 'f', 'G': 'g', 'HH': 'h', 'IH': 'Éª', 'IY': 'i', 'JH': 'Ê¤', 'K': 'k', 'L': 'l', 'M': 'm', 'N': 'n', 'NG': 'Å‹', 'OW': 'oÊŠ', 'OY': 'É”Éª', 'P': 'p', 'R': 'r', 'S': 's', 'SH': 'Êƒ', 'T': 't', 'TH': 'Î¸', 'UH': 'ÊŠ', 'UW': 'u', 'V': 'v', 'W': 'w', 'Y': 'j', 'Z': 'z', 'ZH': 'Ê’',
}

def arpabet_to_ipa(arpabet_phons: List[str]) -> Optional[str]:
    """ARPAbet ìŒì†Œì—´ì„ IPA ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    ipa_phons = [ARPABET_TO_IPA_MAP.get(phon.upper(), '') for phon in arpabet_phons]
    return "".join([p for p in ipa_phons if p])

def calculate_slant_score(phon_list1: List[str], phon_list2: List[str]) -> float:
    """ë‘ ìŒì†Œì—´ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ 0 ë²¡í„°ë¡œ ì±„ì›Œì„œ ê³„ì‚°)"""
    
    len1, len2 = len(phon_list1), len(phon_list2)
    max_len = max(len1, len2)
    
    vec1_list = [get_embedding(p) for p in phon_list1]
    vec2_list = [get_embedding(p) for p in phon_list2]
    
    # ê¸¸ì´ê°€ ë‹¤ë¥¼ ê²½ìš°, ì§§ì€ ìª½ì„ 0 ë²¡í„°ë¡œ ì±„ì›Œì„œ ê¸¸ì´ë¥¼ ë§ì¶¥ë‹ˆë‹¤.
    vec1 = np.concatenate(vec1_list + [np.zeros(5)] * (max_len - len1))
    vec2 = np.concatenate(vec2_list + [np.zeros(5)] * (max_len - len2))
    
    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
        return 0.0

    similarity = 1 - cosine(vec1, vec2)
    return max(0, similarity)


@st.cache_data(show_spinner=False)
def get_rhyme_candidates_with_score(target_word: str, top_n=100) -> Dict:
    """ê°•ì„¸ ëª¨ìŒ ë° ìŠ¬ëœíŠ¸ ë¼ì„ ê·œì¹™ì„ ì ìš©í•˜ì—¬ ë¼ì„ í›„ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    
    target_info = get_rhyme_unit(target_word)
    
    if not target_info:
        return {"target_word": target_word, "target_ipa": "N/A", "target_rhyme_unit": "N/A", "raw_arpabet": "N/A", "candidates": []}

    target_pron_raw, target_onset, target_rhyme_unit, target_vowel = target_info
    target_ipa = arpabet_to_ipa(target_rhyme_unit)
    
    if not target_ipa or not target_rhyme_unit:
        return {"target_word": target_word, "target_ipa": "N/A", "target_rhyme_unit": "N/A", "raw_arpabet": target_pron_raw, "candidates": []}

    target_rhyme_len = len(target_rhyme_unit)
    candidates_list = []
    
    # ----------------------------------------------------------------
    # CMUDict ì „ì²´ ìŠ¤ìº” ë¡œì§
    # ----------------------------------------------------------------
    for word, _ in p_dict.items():
        
        candidate_info = get_rhyme_unit(word)
        if not candidate_info:
            continue
            
        candidate_pron_raw, candidate_onset, candidate_rhyme_unit, candidate_vowel = candidate_info
        
        if word == target_word.lower():
            continue
            
        score = 0.0
        rhyme_type = "Slant/Poor Match"
        
        # A. Perfect Rhyme (ì™„ë²½í•œ ë¼ì„) ê²€ì‚¬
        # 1. ë¼ì„ ìœ ë‹› ê¸¸ì´ê°€ ê°™ì•„ì•¼ í•¨
        if len(candidate_rhyme_unit) == target_rhyme_len:
            # 2. ê°•ì„¸ ëª¨ìŒë¶€í„° ëê¹Œì§€ ìŒì†Œê°€ ì™„ì „íˆ ì¼ì¹˜í•´ì•¼ í•¨
            if candidate_rhyme_unit == target_rhyme_unit:
                # 3. Onset Check: ê°•ì„¸ ëª¨ìŒ ì•ì˜ ë§ˆì§€ë§‰ ìŒì†ŒëŠ” ë‹¬ë¼ì•¼ í•¨ (e.g., 'cat'/'sat'ì€ True Rhyme, 'cat'/'cater'ëŠ” ì•„ë‹˜)
                is_onset_different = (not target_onset or not candidate_onset or target_onset[-1] != candidate_onset[-1])
                
                if is_onset_different:
                    score = 1.0 
                    rhyme_type = "Perfect Rhyme (True Rhyme)"
                # Onsetì´ ê°™ìœ¼ë©´ Slant Rhyme ê³„ì‚°ìœ¼ë¡œ ë„˜ì–´ê° (ì˜ˆì™¸ì ì¸ Near Rhyme)
        
        # B. Slant Rhyme (ë¶ˆì™„ì „ ë¼ì„) ë° Multi-Syllable Rhyme ê²€ì‚¬
        if score < 1.0:
            
            # ë©€í‹°-ìŒì ˆ ë¼ì„ì„ ìœ„í•œ Slant Rhyme ê³„ì‚°
            len_diff = abs(len(candidate_rhyme_unit) - target_rhyme_len)
            
            # ê¸¸ì´ ì°¨ì´ê°€ ìŒì†Œ 2ê°œ ì´í•˜ì¸ ê²½ìš°ë§Œ ê³„ì‚°
            if len_diff <= 2: 
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                slant_score = calculate_slant_score(target_rhyme_unit, candidate_rhyme_unit)
                
                # ì™„ë²½ ë¼ì„ì€ ì•„ë‹ˆì§€ë§Œ, ìŒì†Œ ìœ ì‚¬ë„ê°€ ë†’ì„ ë•Œ
                if slant_score >= 0.85: 
                    score = slant_score
                    rhyme_type = "Multi-Syllable Slant Rhyme"
                elif slant_score >= 0.70:
                    score = slant_score
                    rhyme_type = "Near Rhyme"
                else:
                    continue # ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì œì™¸
            else:
                continue # ê¸¸ì´ê°€ ë„ˆë¬´ ë‹¤ë¥´ë©´ ì œì™¸

        if score > 0.0:
            candidates_list.append({
                "word": word,
                "score": round(score, 4), 
                "ipa": arpabet_to_ipa(candidate_rhyme_unit),
                "rhyme_unit": " ".join(candidate_rhyme_unit),
                "rhyme_type": rhyme_type
            })

    # ì •ë ¬ ë° ê²°ê³¼ ë°˜í™˜
    candidates_list.sort(key=lambda x: x['score'], reverse=True)

    return {
        "target_word": target_word,
        "target_ipa": target_ipa,
        "target_rhyme_unit": " ".join(target_rhyme_unit),
        "raw_arpabet": target_pron_raw,
        "candidates": candidates_list[:top_n]
    }


# =========================================================
# 3. Streamlit UI (ìˆ˜ì •ëœ ë¡œì§ ë°˜ì˜)
# =========================================================

st.set_page_config(page_title="Phonetics Analyzer (Advanced Rhyme)", layout="centered")

st.title("ğŸ¤ CMUDict í†µí•©: ê³ ê¸‰ ë¼ì„ ë¶„ì„ê¸° (ê°•ì„¸ & ìŠ¬ëœíŠ¸ ë°˜ì˜)")
st.caption("âœ… **ë§ˆì§€ë§‰ ê°•ì„¸ ëª¨ìŒ**ë¶€í„° ë¼ì„ ìœ ë‹›ì„ ì¶”ì¶œí•˜ê³ , **ë©€í‹°-ìŒì ˆ ìŠ¬ëœíŠ¸ ë¼ì„**ì„ ìœ„í•œ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")

# ì‚¬ìš©ì ì…ë ¥
input_word = st.text_input("ë¶„ì„í•  ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: magical, mind, computer)", "magical")

if input_word:
    st.subheader(f"ğŸ” '{input_word}'ì— ëŒ€í•œ CMUDict ê¸°ë°˜ ë¶„ì„ ê²°ê³¼")
    
    # ê³„ì‚° ë¡œì§ ì‹¤í–‰
    with st.spinner('CMUDictë¥¼ ìŠ¤ìº”í•˜ê³  ë¼ì„ ìœ ë‹›ì„ ê³„ì‚° ì¤‘...'):
        analysis_result = get_rhyme_candidates_with_score(input_word)
    
    # --- ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ ---
    st.markdown("#### ğŸš¨ ë””ë²„ê¹… ë° ë¶„ì„ ì •ë³´")
    st.markdown(f"**CMUDict ì›ë³¸ ë°œìŒ (ARPAbet):** `{analysis_result.get('raw_arpabet')}`")
    st.markdown(f"**ëŒ€ìƒ ë¼ì„ ìœ ë‹› (ARPAbet):** `{analysis_result['target_rhyme_unit']}`")
    st.markdown(f"**ëŒ€ìƒ ë¼ì„ ìœ ë‹› (IPA):** `{analysis_result['target_ipa']}`")
    
    # 2. ìœ ì‚¬ë„ í…Œì´ë¸” í‘œì‹œ
    st.markdown("---")
    st.markdown("#### CMUDict ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ (ì ìˆ˜ ìˆœ ì •ë ¬)")
    
    if analysis_result['candidates']:
        # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
        data = []
        for c in analysis_result['candidates']:
            data.append({
                "Word": c['word'],
                "Rhyme Unit (ARPAbet)": c['rhyme_unit'],
                "IPA": c['ipa'],
                "Score": f"{c['score']:.4f}",
                "Rhyme Type": c['rhyme_type']
            })
        
        st.dataframe(data, use_container_width=True, hide_index=True)
    else:
        st.warning(f"CMUDictì—ì„œ '{input_word}'ì— ëŒ€í•œ ì ì ˆí•œ ë¼ì„ í›„ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # 3. Geminiê°€ ë°›ì„ API ì‘ë‹µ (JSON)
    st.markdown("---")
    st.markdown("#### ğŸ¤– Geminiì—ê²Œ ì œê³µí•  ìµœì¢… API ì‘ë‹µ (JSON)")
    final_json_output = {
        "target_word": analysis_result["target_word"],
        "target_ipa": analysis_result["target_ipa"],
        "candidates": [{k: v for k, v in c.items() if k not in ['rhyme_unit']} for c in analysis_result["candidates"]]
    }
    st.code(json.dumps(final_json_output, indent=2), language='json')
