import streamlit as st
import numpy as np
from scipy.spatial.distance import cosine
import json
import nltk
from nltk.corpus import cmudict
from typing import List, Tuple, Optional, Dict

# --- CMUDict ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ---
@st.cache_resource(show_spinner="CMUDict ì‚¬ì „ì„ ë¡œë“œ ì¤‘...")
def load_cmudict():
    """CMUDictë¥¼ ë¡œë“œí•˜ê³  í•„ìš”í•œ ê²½ìš° ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        nltk.data.find('corpora/cmudict')
    except LookupError:
        nltk.download('cmudict')
        
    return cmudict.dict()

p_dict = load_cmudict()

# =========================================================
# 1. ìŒì†Œ ì„ë² ë”© ìµœì¢… ì¡°ì • (í™œìŒ/ìœ ìŒ ê³„ì—´ ìœ ì‚¬ì„± ê°•í™”)
# =========================================================

# ARPAbet ê¸°í˜¸ì— ì–¸ì–´í•™ì  íŠ¹ì§• ë°˜ì˜: [ëª¨ìŒ, ë¹„ìŒ, ë°œì„±, ì¡°ìŒìœ„ì¹˜, ì¡°ìŒë°©ë²•]
PHONEME_EMBEDDINGS: Dict[str, np.ndarray] = {
    # Vowels (ëª¨ìŒ): IYì™€ AE ë“± ì£¼ìš” ëª¨ìŒ ì¤‘ìš”ë„ ìœ ì§€
    'AE': np.array([1.0, 0.1, 1.0, 0.2, 0.0]),
    'IY': np.array([0.9, 0.1, 1.0, 0.0, 0.0]),
    'IH': np.array([0.8, 0.1, 1.0, 0.1, 0.0]),
    'AH': np.array([0.7, 0.2, 1.0, 0.5, 0.0]),
    'AY': np.array([0.9, 0.1, 1.0, 0.3, 0.1]), # 'buy you' ê³„ì—´ ë¼ì„ ê°•í™”
    'AO': np.array([0.9, 0.1, 1.0, 0.7, 0.1]), # 'jaw you' ê³„ì—´ ë¼ì„ ê°•í™”
    'ER': np.array([0.6, 0.0, 1.0, 0.5, 0.5]),
    
    # Consonants: T/M ìœ ì‚¬ì„± ìœ ì§€, L/R/Y/W (í™œìŒ/ìœ ìŒ) ìœ ì‚¬ì„± ê°•í™”
    'T': np.array([0.0, 0.7, 0.0, 0.4, 0.9]), 
    'M': np.array([0.0, 0.9, 1.0, 0.2, 0.8]), 
    'D': np.array([0.0, 0.8, 1.0, 0.3, 0.9]),
    'N': np.array([0.0, 0.9, 1.0, 0.3, 0.8]),
    'K': np.array([0.0, 0.5, 0.0, 0.8, 0.9]),
    'G': np.array([0.0, 0.5, 1.0, 0.8, 0.9]),
    'F': np.array([0.0, 0.5, 0.0, 0.1, 0.7]),
    'V': np.array([0.0, 0.5, 1.0, 0.1, 0.7]),
    'S': np.array([0.0, 0.0, 0.0, 0.3, 0.7]),
    'Z': np.array([0.0, 0.0, 1.0, 0.3, 0.7]),
    
    # L/R/Y/W ê³„ì—´: ëª¨ìŒê³¼ ìœ ì‚¬í•œ íŠ¹ì„±(ë†’ì€ 1ë²ˆì§¸ ë²¡í„°)ê³¼ í™œìŒ íŠ¹ì„±(ë‚®ì€ 5ë²ˆì§¸ ë²¡í„°)ì„ ë¶€ì—¬í•˜ì—¬ ìƒí˜¸ ìœ ì‚¬ì„± ê°•í™”
    'L': np.array([0.4, 0.0, 1.0, 0.7, 0.3]),
    'R': np.array([0.5, 0.0, 1.0, 0.5, 0.4]),
    'Y': np.array([0.6, 0.0, 1.0, 0.1, 0.1]), # ëª¨ìŒê³¼ ìœ ì‚¬í•˜ë„ë¡ 1ë²ˆì§¸ ë²¡í„° ë†’ì„
    'W': np.array([0.6, 0.0, 1.0, 0.9, 0.1]), # ëª¨ìŒê³¼ ìœ ì‚¬í•˜ë„ë¡ 1ë²ˆì§¸ ë²¡í„° ë†’ì„
}

def get_embedding(phon: str) -> np.ndarray:
    return PHONEME_EMBEDDINGS.get(phon.upper(), np.zeros(5))

# =========================================================
# 2. í•µì‹¬ í•¨ìˆ˜: ë¼ì„ ìœ ë‹› ì¶”ì¶œ (ê°•ì„¸ ëª¨ìŒ ê¸°ì¤€)
# =========================================================

def get_rhyme_unit(word: str) -> Optional[Tuple[List[str], List[str], List[str]]]:
    """
    ë‹¨ì–´ì˜ ë°œìŒì—ì„œ ë§ˆì§€ë§‰ ê°•ì„¸ ëª¨ìŒ(1 ë˜ëŠ” 2)ì„ ê¸°ì¤€ìœ¼ë¡œ ë¼ì„ ìœ ë‹›ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (ë°˜í™˜: ì›ë³¸ ë°œìŒ, Onset(ë‘ìŒ), Rhyme Unit(ìš´))
    """
    word = word.lower()
    if word not in p_dict:
        return None
        
    pron_raw = p_dict[word][0]
    stress_markers = ['1', '2']
    stress_indices = [i for i, phon in enumerate(pron_raw) if phon[-1] in stress_markers]
    
    if not stress_indices:
        start_index = 0
    else:
        start_index = stress_indices[-1]
        
    onset_raw = pron_raw[:start_index] 
    rhyme_unit_raw = pron_raw[start_index:]
    
    onset_clean = [phon.rstrip('0123') for phon in onset_raw]
    rhyme_unit_clean = [phon.rstrip('0123') for phon in rhyme_unit_raw]

    return pron_raw, onset_clean, rhyme_unit_clean

# ---------------------------------------------------------
# IPA ë° Slant Score ê³„ì‚° í•¨ìˆ˜ (ë³€ë™ ì—†ìŒ)
# ---------------------------------------------------------
ARPABET_TO_IPA_MAP = {
    'AA': 'É‘', 'AE': 'Ã¦', 'AH': 'ÊŒ', 'AO': 'É”', 'AW': 'aÊŠ', 'AY': 'aÉª', 'B': 'b', 'CH': 'Ê§', 'D': 'd', 'DH': 'Ã°', 'EH': 'É›', 'ER': 'É™É¹', 'EY': 'eÉª', 'F': 'f', 'G': 'g', 'HH': 'h', 'IH': 'Éª', 'IY': 'i', 'JH': 'Ê¤', 'K': 'k', 'L': 'l', 'M': 'm', 'N': 'n', 'NG': 'Å‹', 'OW': 'oÊŠ', 'OY': 'É”Éª', 'P': 'p', 'R': 'r', 'S': 's', 'SH': 'Êƒ', 'T': 't', 'TH': 'Î¸', 'UH': 'ÊŠ', 'UW': 'u', 'V': 'v', 'W': 'w', 'Y': 'j', 'Z': 'z', 'ZH': 'Ê’',
}

def arpabet_to_ipa(arpabet_phons: List[str]) -> Optional[str]:
    ipa_phons = [ARPABET_TO_IPA_MAP.get(phon.upper(), '') for phon in arpabet_phons]
    return "".join([p for p in ipa_phons if p])

def calculate_slant_score(phon_list1: List[str], phon_list2: List[str]) -> float:
    len1, len2 = len(phon_list1), len(phon_list2)
    max_len = max(len1, len2)
    
    vec1_list = [get_embedding(p) for p in phon_list1]
    vec2_list = [get_embedding(p) for p in phon_list2]
    
    vec1 = np.concatenate(vec1_list + [np.zeros(5)] * (max_len - len1))
    vec2 = np.concatenate(vec2_list + [np.zeros(5)] * (max_len - len2))
    
    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
        return 0.0

    similarity = 1 - cosine(vec1, vec2)
    return max(0, similarity)


@st.cache_data(show_spinner=False)
def get_rhyme_candidates_with_score(target_word: str, top_n=100) -> Dict:
    
    target_info = get_rhyme_unit(target_word)
    
    if not target_info:
        return {"target_word": target_word, "target_ipa": "N/A", "target_rhyme_unit": "N/A", "raw_arpabet": "N/A", "candidates": []}

    target_pron_raw, target_onset, target_rhyme_unit = target_info
    target_ipa = arpabet_to_ipa(target_rhyme_unit)
    
    if not target_ipa or not target_rhyme_unit:
        return {"target_word": target_word, "target_ipa": "N/A", "target_rhyme_unit": "N/A", "raw_arpabet": target_pron_raw, "candidates": []}

    target_rhyme_len = len(target_rhyme_unit)
    candidates_list = []
    
    # ----------------------------------------------------------------
    # CMUDict ì „ì²´ ìŠ¤ìº” ë¡œì§
    # ----------------------------------------------------------------
    for word, _ in p_dict.items():
        
        candidate_info = get_rhyme_unit(word)
        if not candidate_info:
            continue
            
        candidate_pron_raw, candidate_onset, candidate_rhyme_unit = candidate_info
        
        if word == target_word.lower():
            continue
            
        score = 0.0
        rhyme_type = "Slant/Poor Match"
        
        # A. Perfect Rhyme (ì™„ë²½í•œ ë¼ì„) ê²€ì‚¬
        if len(candidate_rhyme_unit) == target_rhyme_len:
            if candidate_rhyme_unit == target_rhyme_unit:
                is_onset_different = (not target_onset or not candidate_onset or target_onset[-1] != candidate_onset[-1])
                
                if is_onset_different:
                    score = 1.0 
                    rhyme_type = "Perfect Rhyme (True Rhyme)"
        
        # B. Slant Rhyme (ë¶ˆì™„ì „ ë¼ì„) ë° Multi-Syllable Rhyme ê²€ì‚¬
        if score < 1.0:
            
            len_diff = abs(len(candidate_rhyme_unit) - target_rhyme_len)
            
            if len_diff <= 2: 
                
                slant_score = calculate_slant_score(target_rhyme_unit, candidate_rhyme_unit)
                
                # T/M, í™œìŒ ìœ ì‚¬ë„ ê°•í™” ë°˜ì˜: ê¸°ì¤€ì„ 0.95 ì´ìƒìœ¼ë¡œ ì¬ì¡°ì •í•˜ì—¬ ê³ í’ˆì§ˆ ìŠ¬ëœíŠ¸ ë¼ì„ë§Œ Near Perfectë¡œ ë¶„ë¥˜
                if slant_score >= 0.95: 
                    score = slant_score
                    rhyme_type = "Multi-Syllable Slant Rhyme (Near Perfect)"
                elif slant_score >= 0.85:
                    score = slant_score
                    rhyme_type = "Slant Rhyme (Good Match)"
                else:
                    continue 
            else:
                continue 

        if score > 0.0:
            candidates_list.append({
                "word": word,
                "score": round(score, 4), 
                "ipa": arpabet_to_ipa(candidate_rhyme_unit),
                "rhyme_unit": " ".join(candidate_rhyme_unit),
                "rhyme_type": rhyme_type
            })

    candidates_list.sort(key=lambda x: x['score'], reverse=True)

    return {
        "target_word": target_word,
        "target_ipa": target_ipa,
        "target_rhyme_unit": " ".join(target_rhyme_unit),
        "raw_arpabet": target_pron_raw,
        "candidates": candidates_list[:top_n]
    }


# =========================================================
# 3. Streamlit UI 
# =========================================================

st.set_page_config(page_title="Phonetics Analyzer (Eminem Style Rhyme)", layout="centered")

st.title("ğŸ¤ CMUDict í†µí•©: ì—ë¯¸ë„´ ìŠ¤íƒ€ì¼ ê³ ê¸‰ ë¼ì„ ë¶„ì„ê¸° (ìµœì¢…)")
st.caption("âœ… **T/M ë° í™œìŒ(L, R, Y, W) ìœ ì‚¬ë„**ë¥¼ ê°•í™”í•˜ì—¬ **ë©€í‹°-ìŒì ˆ ìŠ¬ëœíŠ¸ ë¼ì„**ì— ë†’ì€ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ìµœì¢… ë²„ì „ì…ë‹ˆë‹¤.")

# ì‚¬ìš©ì ì…ë ¥
input_word = st.text_input("ë¶„ì„í•  ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: critical, together, machine)", "critical")

if input_word:
    st.subheader(f"ğŸ” '{input_word}'ì— ëŒ€í•œ CMUDict ê¸°ë°˜ ë¶„ì„ ê²°ê³¼")
    
    # ê³„ì‚° ë¡œì§ ì‹¤í–‰
    with st.spinner('CMUDictë¥¼ ìŠ¤ìº”í•˜ê³  ë¼ì„ ìœ ë‹›ì„ ê³„ì‚° ì¤‘...'):
        analysis_result = get_rhyme_candidates_with_score(input_word)
    
    # --- ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ ---
    st.markdown("#### ğŸš¨ ë””ë²„ê¹… ë° ë¶„ì„ ì •ë³´")
    st.markdown(f"**CMUDict ì›ë³¸ ë°œìŒ (ARPAbet):** `{analysis_result.get('raw_arpabet')}`")
    st.markdown(f"**ëŒ€ìƒ ë¼ì„ ìœ ë‹› (ARPAbet):** `{analysis_result['target_rhyme_unit']}`")
    st.markdown(f"**ëŒ€ìƒ ë¼ì„ ìœ ë‹› (IPA):** `{analysis_result['target_ipa']}`")
    
    # 2. ìœ ì‚¬ë„ í…Œì´ë¸” í‘œì‹œ
    st.markdown("---")
    st.markdown("#### CMUDict ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ (ì ìˆ˜ ìˆœ ì •ë ¬)")
    
    if analysis_result['candidates']:
        # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
        data = []
        for c in analysis_result['candidates']:
            data.append({
                "Word": c['word'],
                "Rhyme Unit (ARPAbet)": c['rhyme_unit'],
                "IPA": c['ipa'],
                "Score": f"{c['score']:.4f}",
                "Rhyme Type": c['rhyme_type']
            })
        
        st.dataframe(data, use_container_width=True, hide_index=True)
    else:
        st.warning(f"CMUDictì—ì„œ '{input_word}'ì— ëŒ€í•œ ì ì ˆí•œ ë¼ì„ í›„ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # 3. Geminiê°€ ë°›ì„ API ì‘ë‹µ (JSON)
    st.markdown("---")
    st.markdown("#### ğŸ¤– Geminiì—ê²Œ ì œê³µí•  ìµœì¢… API ì‘ë‹µ (JSON)")
    final_json_output = {
        "target_word": analysis_result["target_word"],
        "target_ipa": analysis_result["target_ipa"],
        "candidates": [{k: v for k, v in c.items() if k not in ['rhyme_unit']} for c in analysis_result["candidates"]]
    }
    st.code(json.dumps(final_json_output, indent=2), language='json')
