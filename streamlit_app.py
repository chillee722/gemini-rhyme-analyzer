import streamlit as st
import eng_to_ipa as ipa
import numpy as np
from scipy.spatial.distance import cosine
import json
import nltk
from nltk.corpus import cmudict
import sys
import os

# --- CMUDict ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ---
# Streamlit Cloud í™˜ê²½ì—ì„œ NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œê°€ í•„ìˆ˜ì ì´ë¯€ë¡œ, ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ì¼ë°˜í™”í•©ë‹ˆë‹¤.
@st.cache_resource(show_spinner="CMUDict ì‚¬ì „ì„ ë¡œë“œ ì¤‘...")
def load_cmudict():
    try:
        # CMUDict ë°ì´í„°ê°€ ë¡œì»¬ì— ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        nltk.data.find('corpora/cmudict')
    except LookupError: # NLTK ë°ì´í„°ê°€ ì—†ì„ ë•Œ ë°œìƒí•˜ëŠ” ì¼ë°˜ì ì¸ ì˜ˆì™¸
        # ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
        nltk.download('cmudict')
        
    return cmudict.dict()

p_dict = load_cmudict()

# =========================================================
# 1. ìŒì†Œ ì„ë² ë”© ì •ì˜ (ìœ ì‚¬ë„ ê³„ì‚°ì˜ í•µì‹¬ ë°ì´í„°)
# =========================================================

# (ì˜ˆì‹œ) ê·¼ì‚¬ ë¼ì„ íŒë‹¨ì— ì¤‘ìš”í•œ ìŒì†Œë“¤ì˜ ì„ë² ë”© (5ì°¨ì›)
PHONEME_EMBEDDINGS = {
    'Ã¦': np.array([1.0, 0.0, 0.5, 0.0, 0.0]),  # as in 'cat', 'hat'
    'ÊŒ': np.array([0.9, 0.1, 0.6, 0.0, 0.0]),  # as in 'cut'
    'aÉª': np.array([0.5, 0.8, 0.1, 0.0, 0.0]), # as in 'mind'
    'É›': np.array([0.4, 0.7, 0.2, 0.0, 0.0]),  # as in 'spend'
    'i': np.array([0.2, 0.9, 0.1, 0.0, 0.0]),  # as in 'feel'
    't': np.array([0.0, 1.0, 0.0, 1.0, 0.0]),  # Consonant 't'
    'd': np.array([0.0, 0.9, 0.0, 1.0, 0.1]),  # Consonant 'd' (tì™€ ìœ ì‚¬)
    'n': np.array([0.0, 0.8, 0.1, 1.0, 0.0]),  # Consonant 'n'
    'nd': np.array([0.0, 0.7, 0.1, 1.0, 0.1]), # Consonant cluster 'nd'
    'r': np.array([0.1, 0.0, 0.8, 0.5, 0.5]),
    'ÊŠ': np.array([0.3, 0.6, 0.4, 0.0, 0.0]),  # as in 'good'
    'k': np.array([0.0, 0.5, 0.0, 0.5, 0.0]),  # Consonant 'k'
    'v': np.array([0.0, 0.8, 0.0, 1.0, 0.2]),  # Consonant 'v'
    'l': np.array([0.0, 0.0, 0.7, 0.4, 0.0]),  # Consonant 'l'
}

# =========================================================
# 2. í•µì‹¬ ê³„ì‚° í•¨ìˆ˜ (CMUDict í™œìš© ë¡œì§)
# =========================================================

@st.cache_data(show_spinner=False)
def get_arpabet_and_rhyme_unit(word):
    """CMUDictì—ì„œ ë‹¨ì–´ì˜ ARPAbet ë°œìŒê³¼ ë¼ì„ ìœ ë‹›ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    word = word.lower()
    if word not in p_dict:
        # ë‹¨ì–´ê°€ CMUDictì— ì—†ëŠ” ê²½ìš°
        return None, None, None 

    # CMUDictëŠ” ë‹¤ì¤‘ ë°œìŒì„ ê°€ì§ˆ ìˆ˜ ìˆì§€ë§Œ, ì²« ë²ˆì§¸ ë°œìŒë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    pron = p_dict[word][0] 
    
    rhyme_start_index = -1
    
    # 1. ì£¼ ê°•ì„¸(1)ë¥¼ ë¨¼ì € ì°¾ìŠµë‹ˆë‹¤. (ê°€ì¥ ì¤‘ìš”)
    for i, phon in enumerate(pron):
        if phon.endswith('1'): 
            rhyme_start_index = i
            break
            
    # 2. ì£¼ ê°•ì„¸ê°€ ì—†ìœ¼ë©´ ë¶€ ê°•ì„¸(2)ë¥¼ ì°¾ìŠµë‹ˆë‹¤. (ë‹¤ì¤‘ ìŒì ˆ ë‹¨ì–´ ë³´ì¡°)
    if rhyme_start_index == -1:
        for i, phon in enumerate(pron):
            if phon.endswith('2'):
                rhyme_start_index = i
                break
            
    # 3. ê°•ì„¸ ëª¨ìŒì´ ì „í˜€ ì—†ëŠ” ë‹¨ì–´(í•¨ê»˜, to, a ë“±)ëŠ” ì‹¤íŒ¨ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    if rhyme_start_index == -1:
        return pron, None, None # ì›ë³¸ pronì€ ë°˜í™˜í•˜ì—¬ UIì—ì„œ ë””ë²„ê¹… ê°€ëŠ¥í•˜ë„ë¡ í•¨.

    # ARPAbet ë°œìŒì—ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ ë§ˆí¬ ì œê±°
    clean_arpabet = [phon.rstrip('0123') for phon in pron]
    # ë¼ì„ ìœ ë‹› ì¶”ì¶œ (ê°•ì„¸ ëª¨ìŒë¶€í„° ëê¹Œì§€)
    rhyme_unit = clean_arpabet[rhyme_start_index:]
    
    # ì›ë³¸ pron, í´ë¦° ë²„ì „, ë¼ì„ ìœ ë‹›ì„ ëª¨ë‘ ë°˜í™˜
    return pron, clean_arpabet, rhyme_unit

def arpabet_to_ipa(arpabet_phons):
    """ARPAbet ìŒì†Œì—´ì„ eng-to-ipaë¥¼ ì‚¬ìš©í•˜ì—¬ IPA ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    arpabet_str = ', '.join(arpabet_phons)
    try:
        # eng-to-ipa ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëª¨ë“œì— ì£¼ì˜í•˜ì—¬ IPA ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        # ê³µë°±ê³¼ ê°•ì„¸ ë§ˆí¬ë¥¼ ì œê±°í•˜ì—¬ ê¹”ë”í•œ ìŒì†Œì—´ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
        ipa_str = ipa.convert(arpabet_str, mode='arpabet').strip().replace(' ', '').replace('Ëˆ', '').replace('ËŒ', '')
        return ipa_str
    except Exception:
        return None

def calculate_rhyme_score(ipa1, ipa2):
    """ë‘ IPA ë¬¸ìì—´ì˜ ë²¡í„° ìœ ì‚¬ë„ ì ìˆ˜ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    
    phons1 = list(ipa1)[-3:]
    phons2 = list(ipa2)[-3:]
    
    if not phons1 or not phons2 or len(phons1) != len(phons2):
        return 0.0
    
    vec1_list = [PHONEME_EMBEDDINGS.get(p, np.zeros(5)) for p in phons1]
    vec2_list = [PHONEME_EMBEDDINGS.get(p, np.zeros(5)) for p in phons2]
    
    vec1 = np.concatenate(vec1_list)
    vec2 = np.concatenate(vec2_list)
    
    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
        return 0.0

    similarity = 1 - cosine(vec1, vec2)
    return max(0, similarity)


@st.cache_data(show_spinner=False)
def get_rhyme_candidates_with_score(target_word: str, top_n=100):
    """CMUDict ì „ì²´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë¼ì„ ìœ ë‹›ì´ ì¼ì¹˜í•˜ëŠ” í›„ë³´ë¥¼ ì°¾ê³  ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤."""
    
    # ë°˜í™˜ ê°’ì´ ì„¸ ê°œë¡œ ë³€ê²½ë¨
    target_pron_raw, target_arpabet_clean, target_rhyme_unit = get_arpabet_and_rhyme_unit(target_word)
    
    if not target_rhyme_unit:
        # ë¼ì„ ìœ ë‹› ì¶”ì¶œì— ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ ARPAbetë§Œ ë°˜í™˜í•˜ì—¬ UIì— í‘œì‹œ (ë””ë²„ê¹…ìš©)
        return {"target_word": target_word, "target_ipa": "N/A", "raw_arpabet": target_pron_raw, "candidates": []}

    target_ipa = arpabet_to_ipa(target_rhyme_unit)
    
    candidates_list = []
    
    # ----------------------------------------------------------------
    # CMUDict ì „ì²´ ìŠ¤ìº” ë¡œì§
    # ----------------------------------------------------------------
    for word, pron_list in p_dict.items():
        pron_arpabet = pron_list[0]
        pron_clean = [p.rstrip('0123') for p in pron_arpabet]
        
        if word == target_word.lower() or len(word) <= 2 or len(pron_clean) < len(target_rhyme_unit): 
            continue
            
        # ë ë¶€ë¶„ì´ ë¼ì„ ìœ ë‹›ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸ (Near Rhyme í›„ë³´êµ° í•„í„°ë§)
        if pron_clean[-len(target_rhyme_unit):] == target_rhyme_unit:
            
            candidate_ipa = arpabet_to_ipa(pron_clean)
            if candidate_ipa:
                score = calculate_rhyme_score(target_ipa, candidate_ipa) 
                
                candidates_list.append({
                    "word": word,
                    "score": round(score, 2),
                    "ipa": candidate_ipa
                })

    candidates_list.sort(key=lambda x: x['score'], reverse=True)

    return {
        "target_word": target_word,
        "target_ipa": target_ipa,
        "raw_arpabet": target_pron_raw, # ë””ë²„ê¹…ìš©ìœ¼ë¡œ ì¶”ê°€
        "candidates": candidates_list[:top_n]
    }


# =========================================================
# 3. Streamlit UI (CMUDictê°€ í™œì„±í™”ëœ UI)
# =========================================================

st.set_page_config(page_title="Phonetics Analyzer (CMUDict Integrated)", layout="centered")

st.title("ğŸ¤ CMUDict í†µí•©: ìŒì†Œ ì„ë² ë”© ê·¼ì‚¬ ë¼ì„ ë¶„ì„")
st.caption("âœ… CMUDict ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ ì˜ì–´ ë‹¨ì–´ ê²€ìƒ‰ ê°€ëŠ¥ (ê¸°ë§ í”„ë¡œì íŠ¸ ê°œì„  ì‚¬í•­ ë°˜ì˜)")

st.markdown("""
ì´ íˆ´ì€ **ìˆ˜ë™ ë”•ì…”ë„ˆë¦¬** ëŒ€ì‹  **CMUDict (13ë§Œ ë‹¨ì–´)**ë¥¼ í™œìš©í•˜ì—¬, 
ì…ë ¥ ë‹¨ì–´ì™€ **ìŒì†Œ ìœ ì‚¬ì„±**ì´ ë†’ì€ ëª¨ë“  ë‹¨ì–´ë¥¼ ê²€ìƒ‰í•˜ê³  ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤. 
ì´ JSON ê²°ê³¼ê°€ Geminiì—ê²Œ ì œê³µí•  **API ì‘ë‹µ**ì…ë‹ˆë‹¤.
""")

# ì‚¬ìš©ì ì…ë ¥
input_word = st.text_input("ë¶„ì„í•  ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: tough, mind, heart)", "mind")

if input_word:
    st.subheader(f"ğŸ” '{input_word}'ì— ëŒ€í•œ CMUDict ê¸°ë°˜ ë¶„ì„ ê²°ê³¼")
    
    # ê³„ì‚° ë¡œì§ ì‹¤í–‰
    with st.spinner('CMUDictë¥¼ ìŠ¤ìº”í•˜ê³  ìŒì†Œ ì„ë² ë”©ì„ ê³„ì‚° ì¤‘...'):
        analysis_result = get_rhyme_candidates_with_score(input_word)
    
    # --- ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ ---
    st.markdown("#### ğŸš¨ ë””ë²„ê¹… ì •ë³´ (ë°œí‘œ ì‹œ ìˆ¨ê¹€ ê¶Œì¥)")
    st.markdown(f"**CMUDict ì›ë³¸ ë°œìŒ (ARPAbet):** `{analysis_result.get('raw_arpabet')}`")
    st.markdown(f"**ëŒ€ìƒ ë‹¨ì–´ IPA (ë¼ì„ ìœ ë‹›):** `{analysis_result['target_ipa']}`")
    
    # 2. ìœ ì‚¬ë„ í…Œì´ë¸” í‘œì‹œ
    st.markdown("---")
    st.markdown("#### CMUDict ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 100ê°œ ì¤‘ ì ìˆ˜ ìˆœ ì •ë ¬)")
    
    if analysis_result['candidates']:
        # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
        data = []
        for c in analysis_result['candidates']:
            rhyme_type = "Perfect Rhyme" if c['score'] >= 0.99 else ("Near Rhyme" if c['score'] >= 0.70 else "Slant/Poor Match")
            data.append({
                "Word": c['word'],
                "IPA (Phonetics)": c['ipa'],
                "Phonetic Score": f"{c['score']:.2f}",
                "Rhyme Type": rhyme_type
            })
        
        st.dataframe(data, use_container_width=True, hide_index=True)
    else:
        st.warning(f"CMUDictì—ì„œ '{input_word}'ì— ëŒ€í•œ ë¼ì„ ìœ ë‹›ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë‹¨ì–´ê°€ ì‚¬ì „ì— ì—†ê±°ë‚˜ ë„ˆë¬´ ì§§ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")
        if analysis_result.get('raw_arpabet'):
            st.error("ì˜¤ë¥˜ ì›ì¸: **ì£¼ ê°•ì„¸(1) ë˜ëŠ” ë¶€ ê°•ì„¸(2)**ë¥¼ ì°¾ì§€ ëª»í•˜ì—¬ ë¼ì„ ìœ ë‹› ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¨ì–´ì˜ ê°•ì„¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    # 3. Geminiê°€ ë°›ì„ API ì‘ë‹µ (ë°œí‘œ ê°•ì¡°ì )
    st.markdown("---")
    st.markdown("#### ğŸ¤– Geminiì—ê²Œ ì œê³µí•  ìµœì¢… API ì‘ë‹µ (JSON)")
    # UIì— í‘œì‹œë˜ëŠ” JSONì—ì„œëŠ” ë””ë²„ê¹… ì •ë³´ ì œì™¸
    final_json_output = {
        "target_word": analysis_result["target_word"],
        "target_ipa": analysis_result["target_ipa"],
        "candidates": analysis_result["candidates"]
    }
    st.code(json.dumps(final_json_output, indent=2), language='json')
